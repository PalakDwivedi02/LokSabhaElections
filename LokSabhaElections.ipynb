{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOEgsejjNtD645MigJBBP9I",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PalakDwivedi02/LokSabhaElections/blob/main/LokSabhaElections.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "!pip install requests beautifulsoup4 pandas\n"
      ],
      "metadata": {
        "id": "P8b28u6Pysi7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "import numpy as np\n"
      ],
      "metadata": {
        "id": "xMqtoyfBDNXD"
      },
      "execution_count": 333,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "url = \"https://results.eci.gov.in/PcResultGenJune2024/partywisewinresultState-369.htm\""
      ],
      "metadata": {
        "id": "X7hsOFceDVu-"
      },
      "execution_count": 334,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = requests.get(url)\n",
        "if response.status_code == 200:\n",
        "    print(\"Successfully accessed the website\")\n",
        "else:\n",
        "    print(\"Failed to access the website\")\n",
        "    exit()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FfNqLNZJD4jG",
        "outputId": "8c936de2-637e-429c-de32-35fbf5d58ff4"
      },
      "execution_count": 335,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully accessed the website\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "soup = BeautifulSoup(response.content, 'html.parser')"
      ],
      "metadata": {
        "id": "VpWls-F2FHa3"
      },
      "execution_count": 336,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "table = soup.find('table')\n",
        "\n",
        "if table:\n",
        "    data = []\n",
        "    rows = table.find_all('tr')\n",
        "\n",
        "    for row in rows:\n",
        "        cols = row.find_all(['td', 'th'])\n",
        "        cols = [ele.text.strip() for ele in cols]\n",
        "        data.append(cols)\n",
        "    if len(data) >= 241:\n",
        "        header = data[0]\n",
        "        data = data[1:241]\n",
        "    else:\n",
        "        print(f\"Expected 240 rows, but found {len(data)-1} rows.\")\n",
        "        exit()\n",
        "        df = pd.DataFrame(data, columns=header)\n",
        "\n",
        "        df.to_csv('bjp.csv', index=False)\n",
        "\n",
        "    print(\"Data extracted and saved to bjp.csv\")\n",
        "else:\n",
        "    print(\"Table not found on the webpage\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8OMpwlCQFH0M",
        "outputId": "eccee27a-04ab-4278-e458-b6b8fecd4461"
      },
      "execution_count": 337,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data extracted and saved to bjp.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "url2 = \"https://results.eci.gov.in/PcResultGenJune2024/partywisewinresultState-742.htm\""
      ],
      "metadata": {
        "id": "4sfkfFcyJyUg"
      },
      "execution_count": 338,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = requests.get(url2)\n",
        "if response.status_code == 200:\n",
        "    print(\"Successfully accessed the website\")\n",
        "else:\n",
        "    print(\"Failed to access the website\")\n",
        "    exit()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d16dzClPJ5CH",
        "outputId": "f46e9828-5109-4ad4-e4b0-d580d61d9ba0"
      },
      "execution_count": 339,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully accessed the website\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "soup = BeautifulSoup(response.content, 'html.parser')"
      ],
      "metadata": {
        "id": "djAC56fqKQUK"
      },
      "execution_count": 340,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "table = soup.find('table')\n",
        "\n",
        "if table:\n",
        "    data = []\n",
        "    rows = table.find_all('tr')\n",
        "\n",
        "    for row in rows:\n",
        "        cols = row.find_all(['td', 'th'])\n",
        "        cols = [ele.text.strip() for ele in cols]\n",
        "        data.append(cols)\n",
        "    if len(data) >= 100:\n",
        "        header = data[0]\n",
        "        data = data[1:100]\n",
        "    else:\n",
        "        print(f\"Expected 99 rows, but found {len(data)-1} rows.\")\n",
        "        exit()\n",
        "        df = pd.DataFrame(data, columns=header)\n",
        "\n",
        "        df.to_csv('/content/inc.csv', index=False)\n",
        "\n",
        "    print(\"Data extracted and saved to inc.csv\")\n",
        "else:\n",
        "    print(\"Table not found on the webpage\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F5BlNrCnKjnb",
        "outputId": "7c04eabb-5b3e-494a-93f3-bef520dad0fc"
      },
      "execution_count": 341,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data extracted and saved to inc.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "url3 = \"https://results.eci.gov.in/PcResultGenJune2024/partywisewinresultState-1680.htm\""
      ],
      "metadata": {
        "id": "_YD6tib7Nh2z"
      },
      "execution_count": 342,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = requests.get(url3)\n",
        "\n",
        "if response.status_code == 200:\n",
        "    print(\"Successfully accessed the website\")\n",
        "else:\n",
        "    print(\"Failed to access the website\")\n",
        "    exit()\n",
        "\n",
        "soup = BeautifulSoup(response.content, 'html.parser')\n",
        "table = soup.find('table')\n",
        "\n",
        "if table:\n",
        "    data = []\n",
        "    rows = table.find_all('tr')\n",
        "\n",
        "    for row in rows:\n",
        "        cols = row.find_all(['td', 'th'])\n",
        "        cols = [ele.text.strip() for ele in cols]\n",
        "        data.append(cols)\n",
        "\n",
        "    if len(data) >= 38:\n",
        "        header = data[0]\n",
        "        data = data[1:38]\n",
        "    else:\n",
        "        print(f\"Expected 37 rows, but found {len(data)-1} rows.\")\n",
        "        exit()\n",
        "\n",
        "    df = pd.DataFrame(data, columns=header)\n",
        "    file_path = '/content/sp.csv'\n",
        "    df.to_csv(file_path, index=False)\n",
        "\n",
        "    print(f\"Data extracted and saved to {file_path}\")\n",
        "else:\n",
        "    print(\"Table not found on the webpage\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zw2XW8xNNntm",
        "outputId": "0fd83999-f552-495a-ed5a-765b24896504"
      },
      "execution_count": 343,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully accessed the website\n",
            "Data extracted and saved to /content/sp.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "url_aitc = \"https://results.eci.gov.in/PcResultGenJune2024/partywisewinresultState-140.htm\"\n",
        "\n",
        "response = requests.get(url_aitc)\n",
        "\n",
        "if response.status_code == 200:\n",
        "    print(\"Successfully accessed the website\")\n",
        "else:\n",
        "    print(\"Failed to access the website\")\n",
        "    exit()\n",
        "soup = BeautifulSoup(response.content, 'html.parser')\n",
        "\n",
        "table = soup.find('table')\n",
        "\n",
        "if table:\n",
        "    data = []\n",
        "    rows = table.find_all('tr')\n",
        "\n",
        "    for row in rows:\n",
        "        cols = row.find_all(['td', 'th'])\n",
        "        cols = [ele.text.strip() for ele in cols]\n",
        "        data.append(cols)\n",
        "\n",
        "    if len(data) >= 30:\n",
        "        header = data[0]\n",
        "        data = data[1:30]\n",
        "\n",
        "        df = pd.DataFrame(data, columns=header)\n",
        "        file_path = '/content/aitc.csv'\n",
        "        df.to_csv(file_path, index=False)\n",
        "\n",
        "        print(f\"Data extracted and saved to {file_path}\")\n",
        "    else:\n",
        "        print(f\"Expected 29 rows, but found {len(data)-1} rows.\")\n",
        "        exit()\n",
        "else:\n",
        "    print(\"Table not found on the webpage\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oFRQkHTUQyEt",
        "outputId": "c65db5d5-7121-4731-c467-84e18f2020cd"
      },
      "execution_count": 344,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully accessed the website\n",
            "Data extracted and saved to /content/aitc.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "url_tdp = \"https://results.eci.gov.in/PcResultGenJune2024/partywisewinresultState-1745.htm\"\n",
        "\n",
        "response = requests.get(url_tdp)\n",
        "\n",
        "if response.status_code == 200:\n",
        "    print(\"Successfully accessed the website\")\n",
        "else:\n",
        "    print(\"Failed to access the website\")\n",
        "    exit()\n",
        "\n",
        "soup = BeautifulSoup(response.content, 'html.parser')\n",
        "\n",
        "table = soup.find('table')\n",
        "\n",
        "if table:\n",
        "    data = []\n",
        "    rows = table.find_all('tr')\n",
        "\n",
        "    for row in rows:\n",
        "        cols = row.find_all(['td', 'th'])\n",
        "        cols = [ele.text.strip() for ele in cols]\n",
        "        data.append(cols)\n",
        "\n",
        "    if len(data) >= 17:\n",
        "        header = data[0]\n",
        "        data = data[1:17]\n",
        "\n",
        "        df = pd.DataFrame(data, columns=header)\n",
        "        file_path = '/content/tdp.csv'\n",
        "        df.to_csv(file_path, index=False)\n",
        "\n",
        "        print(f\"Data extracted and saved to {file_path}\")\n",
        "    else:\n",
        "        print(f\"Expected 16 rows, but found {len(data)-1} rows.\")\n",
        "        exit()\n",
        "else:\n",
        "    print(\"Table not found on the webpage\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "deTeEW6qRFbP",
        "outputId": "a8e40ebb-6c41-4042-a3df-e58e16f4946e"
      },
      "execution_count": 345,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully accessed the website\n",
            "Data extracted and saved to /content/tdp.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "url_dmk= \"https://results.eci.gov.in/PcResultGenJune2024/partywisewinresultState-582.htm\"\n",
        "\n",
        "response = requests.get(url_dmk)\n",
        "\n",
        "if response.status_code == 200:\n",
        "    print(\"Successfully accessed the website\")\n",
        "else:\n",
        "    print(\"Failed to access the website\")\n",
        "    exit()\n",
        "\n",
        "soup = BeautifulSoup(response.content, 'html.parser')\n",
        "\n",
        "table = soup.find('table')\n",
        "\n",
        "if table:\n",
        "    data = []\n",
        "    rows = table.find_all('tr')\n",
        "\n",
        "    for row in rows:\n",
        "        cols = row.find_all(['td', 'th'])\n",
        "        cols = [ele.text.strip() for ele in cols]\n",
        "        data.append(cols)\n",
        "\n",
        "    if len(data) >= 23:\n",
        "        header = data[0]\n",
        "        data = data[1:23]\n",
        "\n",
        "        df = pd.DataFrame(data, columns=header)\n",
        "        file_path = '/content/dmk.csv'\n",
        "        df.to_csv(file_path, index=False)\n",
        "\n",
        "        print(f\"Data extracted and saved to {file_path}\")\n",
        "    else:\n",
        "        print(f\"Expected 22 rows, but found {len(data)-1} rows.\")\n",
        "        exit()\n",
        "else:\n",
        "    print(\"Table not found on the webpage\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6dtB5rKLRdUF",
        "outputId": "1f6245f6-a637-4741-ccef-9ae06bd09664"
      },
      "execution_count": 346,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully accessed the website\n",
            "Data extracted and saved to /content/dmk.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "url_jd = \"https://results.eci.gov.in/PcResultGenJune2024/partywisewinresultState-805.htm\"\n",
        "\n",
        "response = requests.get(url_jd)\n",
        "\n",
        "if response.status_code == 200:\n",
        "    print(\"Successfully accessed the website\")\n",
        "else:\n",
        "    print(\"Failed to access the website\")\n",
        "    exit()\n",
        "\n",
        "soup = BeautifulSoup(response.content, 'html.parser')\n",
        "\n",
        "table = soup.find('table')\n",
        "\n",
        "if table:\n",
        "    data = []\n",
        "    rows = table.find_all('tr')\n",
        "\n",
        "    for row in rows:\n",
        "        cols = row.find_all(['td', 'th'])\n",
        "        cols = [ele.text.strip() for ele in cols]\n",
        "        data.append(cols)\n",
        "\n",
        "    if len(data) >= 13:\n",
        "        header = data[0]\n",
        "        data = data[1:13]\n",
        "\n",
        "        df = pd.DataFrame(data, columns=header)\n",
        "        file_path = '/content/jd.csv'\n",
        "        df.to_csv(file_path, index=False)\n",
        "\n",
        "        print(f\"Data extracted and saved to {file_path}\")\n",
        "    else:\n",
        "        print(f\"Expected 12 rows, but found {len(data)-1} rows.\")\n",
        "        exit()\n",
        "else:\n",
        "    print(\"Table not found on the webpage\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R-Hd3yzMRpXs",
        "outputId": "a7014b27-5bc1-4bda-b59a-9da9b0cd305a"
      },
      "execution_count": 347,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully accessed the website\n",
            "Data extracted and saved to /content/jd.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "url_ss = \"https://results.eci.gov.in/PcResultGenJune2024/partywisewinresultState-3369.htm\"\n",
        "\n",
        "response = requests.get(url_ss)\n",
        "\n",
        "if response.status_code == 200:\n",
        "    print(\"Successfully accessed the website\")\n",
        "else:\n",
        "    print(\"Failed to access the website\")\n",
        "    exit()\n",
        "\n",
        "soup = BeautifulSoup(response.content, 'html.parser')\n",
        "\n",
        "table = soup.find('table')\n",
        "\n",
        "if table:\n",
        "    data = []\n",
        "    rows = table.find_all('tr')\n",
        "\n",
        "    for row in rows:\n",
        "        cols = row.find_all(['td', 'th'])\n",
        "        cols = [ele.text.strip() for ele in cols]\n",
        "        data.append(cols)\n",
        "\n",
        "    if len(data) >= 10:\n",
        "        header = data[0]\n",
        "        data = data[1:10]\n",
        "\n",
        "        df = pd.DataFrame(data, columns=header)\n",
        "        file_path = f'/content/ss.csv'\n",
        "        df.to_csv(file_path, index=False)\n",
        "\n",
        "        print(f\"Data extracted and saved to {file_path}\")\n",
        "    else:\n",
        "        print(f\"Expected 9 rows, but found {len(data)-1} rows.\")\n",
        "        exit()\n",
        "else:\n",
        "    print(\"Table not found on the webpage\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HLe4NZWpYAbA",
        "outputId": "05fb3856-5f7e-424a-a609-3725694a9cad"
      },
      "execution_count": 348,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully accessed the website\n",
            "Data extracted and saved to /content/ss.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "url_ncp = \"https://results.eci.gov.in/PcResultGenJune2024/partywisewinresultState-3620.htm\"\n",
        "\n",
        "response = requests.get(url_ncp)\n",
        "\n",
        "if response.status_code == 200:\n",
        "    print(\"Successfully accessed the website\")\n",
        "else:\n",
        "    print(\"Failed to access the website\")\n",
        "    exit()\n",
        "\n",
        "soup = BeautifulSoup(response.content, 'html.parser')\n",
        "\n",
        "table = soup.find('table')\n",
        "\n",
        "if table:\n",
        "    data = []\n",
        "    rows = table.find_all('tr')\n",
        "\n",
        "    for row in rows:\n",
        "        cols = row.find_all(['td', 'th'])\n",
        "        cols = [ele.text.strip() for ele in cols]\n",
        "        data.append(cols)\n",
        "\n",
        "    if len(data) >= 9:\n",
        "        header = data[0]\n",
        "        data = data[1:9]\n",
        "\n",
        "        df = pd.DataFrame(data, columns=header)\n",
        "        file_path = f'/content/ncp.csv'\n",
        "        df.to_csv(file_path, index=False)\n",
        "\n",
        "        print(f\"Data extracted and saved to {file_path}\")\n",
        "    else:\n",
        "        print(f\"Expected 8 rows, but found {len(data)-1} rows.\")\n",
        "        exit()\n",
        "else:\n",
        "    print(\"Table not found on the webpage\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uyHGvVlhYEOt",
        "outputId": "f0d96a8f-0825-4939-f4e1-0b0fa4961940"
      },
      "execution_count": 349,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully accessed the website\n",
            "Data extracted and saved to /content/ncp.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "url_shs = \"https://results.eci.gov.in/PcResultGenJune2024/partywisewinresultState-3529.htm\"\n",
        "\n",
        "response = requests.get(url_shs)\n",
        "\n",
        "if response.status_code == 200:\n",
        "    print(\"Successfully accessed the website\")\n",
        "else:\n",
        "    print(\"Failed to access the website\")\n",
        "    exit()\n",
        "\n",
        "soup = BeautifulSoup(response.content, 'html.parser')\n",
        "\n",
        "table = soup.find('table')\n",
        "\n",
        "if table:\n",
        "    data = []\n",
        "    rows = table.find_all('tr')\n",
        "\n",
        "    for row in rows:\n",
        "        cols = row.find_all(['td', 'th'])\n",
        "        cols = [ele.text.strip() for ele in cols]\n",
        "        data.append(cols)\n",
        "\n",
        "    if len(data) >= 8:\n",
        "        header = data[0]\n",
        "        data = data[1:8]\n",
        "\n",
        "        df = pd.DataFrame(data, columns=header)\n",
        "        file_path = f'/content/shs.csv'\n",
        "        df.to_csv(file_path, index=False)\n",
        "\n",
        "        print(f\"Data extracted and saved to {file_path}\")\n",
        "    else:\n",
        "        print(f\"Expected 7 rows, but found {len(data)-1} rows.\")\n",
        "        exit()\n",
        "else:\n",
        "    print(\"Table not found on the webpage\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ctikL7GpYZuu",
        "outputId": "75669b35-9432-44fd-8fd1-cf5e1d16f1ea"
      },
      "execution_count": 350,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully accessed the website\n",
            "Data extracted and saved to /content/shs.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "url_ljp = \"https://results.eci.gov.in/PcResultGenJune2024/partywisewinresultState-3165.htm\"\n",
        "\n",
        "response = requests.get(url_ljp)\n",
        "\n",
        "if response.status_code == 200:\n",
        "    print(\"Successfully accessed the website\")\n",
        "else:\n",
        "    print(\"Failed to access the website\")\n",
        "    exit()\n",
        "\n",
        "soup = BeautifulSoup(response.content, 'html.parser')\n",
        "\n",
        "table = soup.find('table')\n",
        "\n",
        "if table:\n",
        "    data = []\n",
        "    rows = table.find_all('tr')\n",
        "\n",
        "    for row in rows:\n",
        "        cols = row.find_all(['td', 'th'])\n",
        "        cols = [ele.text.strip() for ele in cols]\n",
        "        data.append(cols)\n",
        "\n",
        "    if len(data) >= 6:\n",
        "        header = data[0]\n",
        "        data = data[1:6]\n",
        "\n",
        "        df = pd.DataFrame(data, columns=header)\n",
        "        file_path = f'/content/ljp.csv'\n",
        "        df.to_csv(file_path, index=False)\n",
        "\n",
        "        print(f\"Data extracted and saved to {file_path}\")\n",
        "    else:\n",
        "        print(f\"Expected 5 rows, but found {len(data)-1} rows.\")\n",
        "        exit()\n",
        "else:\n",
        "    print(\"Table not found on the webpage\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xsomQawGYl7I",
        "outputId": "44048677-0436-463b-f45a-a79cf08ac725"
      },
      "execution_count": 351,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully accessed the website\n",
            "Data extracted and saved to /content/ljp.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "url_ysr = \"https://results.eci.gov.in/PcResultGenJune2024/partywisewinresultState-1888.htm\"\n",
        "\n",
        "response = requests.get(url_ysr)\n",
        "\n",
        "if response.status_code == 200:\n",
        "    print(\"Successfully accessed the website\")\n",
        "else:\n",
        "    print(\"Failed to access the website\")\n",
        "    exit()\n",
        "\n",
        "soup = BeautifulSoup(response.content, 'html.parser')\n",
        "\n",
        "table = soup.find('table')\n",
        "\n",
        "if table:\n",
        "    data = []\n",
        "    rows = table.find_all('tr')\n",
        "\n",
        "    for row in rows:\n",
        "        cols = row.find_all(['td', 'th'])\n",
        "        cols = [ele.text.strip() for ele in cols]\n",
        "        data.append(cols)\n",
        "\n",
        "    if len(data) >= 5:\n",
        "        header = data[0]\n",
        "        data = data[1:5]\n",
        "\n",
        "        df = pd.DataFrame(data, columns=header)\n",
        "        file_path = f'/content/ysr.csv'\n",
        "        df.to_csv(file_path, index=False)\n",
        "\n",
        "        print(f\"Data extracted and saved to {file_path}\")\n",
        "    else:\n",
        "        print(f\"Expected 4 rows, but found {len(data)-1} rows.\")\n",
        "        exit()\n",
        "else:\n",
        "    print(\"Table not found on the webpage\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4SuFt8m3Ytgq",
        "outputId": "1faf07b7-9bff-4700-da6c-f8cfbdcf47bc"
      },
      "execution_count": 352,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully accessed the website\n",
            "Data extracted and saved to /content/ysr.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "url_rjd = \"https://results.eci.gov.in/PcResultGenJune2024/partywisewinresultState-1420.htm\"\n",
        "\n",
        "response = requests.get(url_rjd)\n",
        "\n",
        "if response.status_code == 200:\n",
        "    print(\"Successfully accessed the website\")\n",
        "else:\n",
        "    print(\"Failed to access the website\")\n",
        "    exit()\n",
        "\n",
        "soup = BeautifulSoup(response.content, 'html.parser')\n",
        "\n",
        "table = soup.find('table')\n",
        "\n",
        "if table:\n",
        "    data = []\n",
        "    rows = table.find_all('tr')\n",
        "\n",
        "    for row in rows:\n",
        "        cols = row.find_all(['td', 'th'])\n",
        "        cols = [ele.text.strip() for ele in cols]\n",
        "        data.append(cols)\n",
        "\n",
        "    if len(data) >= 5:\n",
        "        header = data[0]\n",
        "        data = data[1:5]\n",
        "\n",
        "        df = pd.DataFrame(data, columns=header)\n",
        "        file_path = f'/content/rjd.csv'\n",
        "        df.to_csv(file_path, index=False)\n",
        "\n",
        "        print(f\"Data extracted and saved to {file_path}\")\n",
        "    else:\n",
        "        print(f\"Expected 4 rows, but found {len(data)-1} rows.\")\n",
        "        exit()\n",
        "else:\n",
        "    print(\"Table not found on the webpage\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bdmJc9RwY-W_",
        "outputId": "e56ed905-532d-4de0-d030-42e7bbe438cf"
      },
      "execution_count": 353,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully accessed the website\n",
            "Data extracted and saved to /content/rjd.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "url_cpi = \"https://results.eci.gov.in/PcResultGenJune2024/partywisewinresultState-547.htm\"\n",
        "\n",
        "response = requests.get(url_cpi)\n",
        "\n",
        "if response.status_code == 200:\n",
        "    print(\"Successfully accessed the website\")\n",
        "else:\n",
        "    print(\"Failed to access the website\")\n",
        "    exit()\n",
        "\n",
        "soup = BeautifulSoup(response.content, 'html.parser')\n",
        "\n",
        "table = soup.find('table')\n",
        "\n",
        "if table:\n",
        "    data = []\n",
        "    rows = table.find_all('tr')\n",
        "\n",
        "    for row in rows:\n",
        "        cols = row.find_all(['td', 'th'])\n",
        "        cols = [ele.text.strip() for ele in cols]\n",
        "        data.append(cols)\n",
        "\n",
        "    if len(data) >= 5:\n",
        "        header = data[0]\n",
        "        data = data[1:5]\n",
        "\n",
        "        df = pd.DataFrame(data, columns=header)\n",
        "        file_path = f'/content/cpi.csv'\n",
        "        df.to_csv(file_path, index=False)\n",
        "\n",
        "        print(f\"Data extracted and saved to {file_path}\")\n",
        "    else:\n",
        "        print(f\"Expected 4 rows, but found {len(data)-1} rows.\")\n",
        "        exit()\n",
        "else:\n",
        "    print(\"Table not found on the webpage\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-MJBcjzuZEWn",
        "outputId": "32c3bc80-3265-4e99-abae-a1023c8f86de"
      },
      "execution_count": 354,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully accessed the website\n",
            "Data extracted and saved to /content/cpi.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "url_ss = \"https://results.eci.gov.in/PcResultGenJune2024/partywisewinresultState-3369.htm\"\n",
        "\n",
        "response = requests.get(url_ss)\n",
        "\n",
        "if response.status_code == 200:\n",
        "    print(\"Successfully accessed the website\")\n",
        "else:\n",
        "    print(\"Failed to access the website\")\n",
        "    exit()\n",
        "\n",
        "soup = BeautifulSoup(response.content, 'html.parser')\n",
        "\n",
        "table = soup.find('table')\n",
        "\n",
        "if table:\n",
        "    data = []\n",
        "    rows = table.find_all('tr')\n",
        "\n",
        "    for row in rows:\n",
        "        cols = row.find_all(['td', 'th'])\n",
        "        cols = [ele.text.strip() for ele in cols]\n",
        "        data.append(cols)\n",
        "\n",
        "    if len(data) >= 10:\n",
        "        header = data[0]\n",
        "        data = data[1:10]\n",
        "\n",
        "        df = pd.DataFrame(data, columns=header)\n",
        "        file_path = f'/content/ss.csv'\n",
        "        df.to_csv(file_path, index=False)\n",
        "\n",
        "        print(f\"Data extracted and saved to {file_path}\")\n",
        "    else:\n",
        "        print(f\"Expected 9 rows, but found {len(data)-1} rows.\")\n",
        "        exit()\n",
        "else:\n",
        "    print(\"Table not found on the webpage\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PVCaPMsTZHJm",
        "outputId": "9f592c0a-ba26-4a9e-8202-dc604ffb8635"
      },
      "execution_count": 355,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully accessed the website\n",
            "Data extracted and saved to /content/ss.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "url_iuml = \"https://results.eci.gov.in/PcResultGenJune2024/partywisewinresultState-772.htm\"\n",
        "\n",
        "response = requests.get(url_iuml)\n",
        "\n",
        "if response.status_code == 200:\n",
        "    print(\"Successfully accessed the website\")\n",
        "else:\n",
        "    print(\"Failed to access the website\")\n",
        "    exit()\n",
        "\n",
        "soup = BeautifulSoup(response.content, 'html.parser')\n",
        "\n",
        "table = soup.find('table')\n",
        "\n",
        "if table:\n",
        "    data = []\n",
        "    rows = table.find_all('tr')\n",
        "\n",
        "    for row in rows:\n",
        "        cols = row.find_all(['td', 'th'])\n",
        "        cols = [ele.text.strip() for ele in cols]\n",
        "        data.append(cols)\n",
        "\n",
        "    if len(data) >= 4:\n",
        "        header = data[0]\n",
        "        data = data[1:4]\n",
        "\n",
        "        df = pd.DataFrame(data, columns=header)\n",
        "        file_name = 'iuml.csv'\n",
        "        file_path = f'/content/{file_name}'\n",
        "        df.to_csv(file_path, index=False)\n",
        "\n",
        "        print(f\"Data extracted and saved to {file_path}\")\n",
        "    else:\n",
        "        print(f\"Expected 3 rows, but found {len(data)-1} rows.\")\n",
        "        exit()\n",
        "else:\n",
        "    print(\"Table not found on the webpage\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o16t60mECZV4",
        "outputId": "796d4256-8a8f-42cb-ad01-ecaf9ddd0428"
      },
      "execution_count": 356,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully accessed the website\n",
            "Data extracted and saved to /content/iuml.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "url_aap = \"https://results.eci.gov.in/PcResultGenJune2024/partywisewinresultState-1.htm\"\n",
        "\n",
        "response = requests.get(url_aap)\n",
        "\n",
        "if response.status_code == 200:\n",
        "    print(\"Successfully accessed the website\")\n",
        "else:\n",
        "    print(\"Failed to access the website\")\n",
        "    exit()\n",
        "\n",
        "soup = BeautifulSoup(response.content, 'html.parser')\n",
        "\n",
        "table = soup.find('table')\n",
        "\n",
        "if table:\n",
        "    data = []\n",
        "    rows = table.find_all('tr')\n",
        "\n",
        "    for row in rows:\n",
        "        cols = row.find_all(['td', 'th'])\n",
        "        cols = [ele.text.strip() for ele in cols]\n",
        "        data.append(cols)\n",
        "\n",
        "    if len(data) >= 4:\n",
        "        header = data[0]\n",
        "        data = data[1:4]\n",
        "\n",
        "        df = pd.DataFrame(data, columns=header)\n",
        "        file_name = 'aap.csv'\n",
        "        file_path = f'/content/{file_name}'\n",
        "        df.to_csv(file_path, index=False)\n",
        "\n",
        "        print(f\"Data extracted and saved to {file_path}\")\n",
        "    else:\n",
        "        print(f\"Expected 3 rows, but found {len(data)-1} rows.\")\n",
        "        exit()\n",
        "else:\n",
        "    print(\"Table not found on the webpage\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aw65kN4-ClNV",
        "outputId": "b2f0f34d-76be-4d88-f43f-19a17707e5a0"
      },
      "execution_count": 357,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully accessed the website\n",
            "Data extracted and saved to /content/aap.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "url_jmm = \"https://results.eci.gov.in/PcResultGenJune2024/partywisewinresultState-852.htm\"\n",
        "\n",
        "response = requests.get(url_jmm)\n",
        "\n",
        "if response.status_code == 200:\n",
        "    print(\"Successfully accessed the website\")\n",
        "else:\n",
        "    print(\"Failed to access the website\")\n",
        "    exit()\n",
        "\n",
        "soup = BeautifulSoup(response.content, 'html.parser')\n",
        "\n",
        "table = soup.find('table')\n",
        "\n",
        "if table:\n",
        "    data = []\n",
        "    rows = table.find_all('tr')\n",
        "\n",
        "    for row in rows:\n",
        "        cols = row.find_all(['td', 'th'])\n",
        "        cols = [ele.text.strip() for ele in cols]\n",
        "        data.append(cols)\n",
        "\n",
        "    if len(data) >= 4:\n",
        "        header = data[0]\n",
        "        data = data[1:4]\n",
        "\n",
        "        df = pd.DataFrame(data, columns=header)\n",
        "        file_name = 'jmm.csv'\n",
        "        file_path = f'/content/{file_name}'\n",
        "        df.to_csv(file_path, index=False)\n",
        "\n",
        "        print(f\"Data extracted and saved to {file_path}\")\n",
        "    else:\n",
        "        print(f\"Expected 3 rows, but found {len(data)-1} rows.\")\n",
        "        exit()\n",
        "else:\n",
        "    print(\"Table not found on the webpage\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nUhCpNEECqDj",
        "outputId": "8328e001-1127-494b-c5e4-8b5e297dfaa5"
      },
      "execution_count": 358,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully accessed the website\n",
            "Data extracted and saved to /content/jmm.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "url_jnp = \"https://results.eci.gov.in/PcResultGenJune2024/partywisewinresultState-860.htm\"\n",
        "\n",
        "response = requests.get(url_jnp)\n",
        "\n",
        "if response.status_code == 200:\n",
        "    print(\"Successfully accessed the website\")\n",
        "else:\n",
        "    print(\"Failed to access the website\")\n",
        "    exit()\n",
        "\n",
        "soup = BeautifulSoup(response.content, 'html.parser')\n",
        "\n",
        "table = soup.find('table')\n",
        "\n",
        "if table:\n",
        "    data = []\n",
        "    rows = table.find_all('tr')\n",
        "\n",
        "    for row in rows:\n",
        "        cols = row.find_all(['td', 'th'])\n",
        "        cols = [ele.text.strip() for ele in cols]\n",
        "        data.append(cols)\n",
        "\n",
        "    if len(data) >= 3:\n",
        "        header = data[0]\n",
        "        data = data[1:3]\n",
        "\n",
        "        df = pd.DataFrame(data, columns=header)\n",
        "        file_name = 'jnp.csv'\n",
        "        file_path = f'/content/{file_name}'\n",
        "        df.to_csv(file_path, index=False)\n",
        "\n",
        "        print(f\"Data extracted and saved to {file_path}\")\n",
        "    else:\n",
        "        print(f\"Expected 2 rows, but found {len(data)-1} rows.\")\n",
        "        exit()\n",
        "else:\n",
        "    print(\"Table not found on the webpage\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bLfP3f31Cu9_",
        "outputId": "1f360a31-9680-4ebb-b19c-d61626e41e7d"
      },
      "execution_count": 359,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully accessed the website\n",
            "Data extracted and saved to /content/jnp.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "url_ml = \"https://results.eci.gov.in/PcResultGenJune2024/partywisewinresultState-545.htm\"\n",
        "\n",
        "response = requests.get(url_ml)\n",
        "\n",
        "if response.status_code == 200:\n",
        "    print(\"Successfully accessed the website\")\n",
        "else:\n",
        "    print(\"Failed to access the website\")\n",
        "    exit()\n",
        "\n",
        "soup = BeautifulSoup(response.content, 'html.parser')\n",
        "\n",
        "table = soup.find('table')\n",
        "\n",
        "if table:\n",
        "    data = []\n",
        "    rows = table.find_all('tr')\n",
        "\n",
        "    for row in rows:\n",
        "        cols = row.find_all(['td', 'th'])\n",
        "        cols = [ele.text.strip() for ele in cols]\n",
        "        data.append(cols)\n",
        "\n",
        "    if len(data) >= 3:\n",
        "        header = data[0]\n",
        "        data = data[1:3]\n",
        "\n",
        "        df = pd.DataFrame(data, columns=header)\n",
        "        file_name = 'ml.csv'\n",
        "        file_path = f'/content/{file_name}'\n",
        "        df.to_csv(file_path, index=False)\n",
        "\n",
        "        print(f\"Data extracted and saved to {file_path}\")\n",
        "    else:\n",
        "        print(f\"Expected 2 rows, but found {len(data)-1} rows.\")\n",
        "        exit()\n",
        "else:\n",
        "    print(\"Table not found on the webpage\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iQ2UIO62Cy3n",
        "outputId": "c277f23d-4456-4b8d-e123-1dcdfaf559e0"
      },
      "execution_count": 360,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully accessed the website\n",
            "Data extracted and saved to /content/ml.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "url_jds = \"https://results.eci.gov.in/PcResultGenJune2024/partywisewinresultState-804.htm\"\n",
        "\n",
        "response = requests.get(url_jds)\n",
        "\n",
        "if response.status_code == 200:\n",
        "    print(\"Successfully accessed the website\")\n",
        "else:\n",
        "    print(\"Failed to access the website\")\n",
        "    exit()\n",
        "\n",
        "soup = BeautifulSoup(response.content, 'html.parser')\n",
        "\n",
        "table = soup.find('table')\n",
        "\n",
        "if table:\n",
        "    data = []\n",
        "    rows = table.find_all('tr')\n",
        "\n",
        "    for row in rows:\n",
        "        cols = row.find_all(['td', 'th'])\n",
        "        cols = [ele.text.strip() for ele in cols]\n",
        "        data.append(cols)\n",
        "\n",
        "    if len(data) >= 3:\n",
        "        header = data[0]\n",
        "        data = data[1:3]\n",
        "\n",
        "        df = pd.DataFrame(data, columns=header)\n",
        "        file_name = 'jds.csv'\n",
        "        file_path = f'/content/{file_name}'\n",
        "        df.to_csv(file_path, index=False)\n",
        "\n",
        "        print(f\"Data extracted and saved to {file_path}\")\n",
        "    else:\n",
        "        print(f\"Expected 2 rows, but found {len(data)-1} rows.\")\n",
        "        exit()\n",
        "else:\n",
        "    print(\"Table not found on the webpage\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kEpSpwijC2i4",
        "outputId": "d8972301-8d1c-4b52-b9e5-b7d65fcb00ab"
      },
      "execution_count": 361,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully accessed the website\n",
            "Data extracted and saved to /content/jds.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "url_vck = \"https://results.eci.gov.in/PcResultGenJune2024/partywisewinresultState-1847.htm\"\n",
        "\n",
        "response = requests.get(url_vck)\n",
        "\n",
        "if response.status_code == 200:\n",
        "    print(\"Successfully accessed the website\")\n",
        "else:\n",
        "    print(\"Failed to access the website\")\n",
        "    exit()\n",
        "\n",
        "soup = BeautifulSoup(response.content, 'html.parser')\n",
        "\n",
        "table = soup.find('table')\n",
        "\n",
        "if table:\n",
        "    data = []\n",
        "    rows = table.find_all('tr')\n",
        "\n",
        "    for row in rows:\n",
        "        cols = row.find_all(['td', 'th'])\n",
        "        cols = [ele.text.strip() for ele in cols]\n",
        "        data.append(cols)\n",
        "\n",
        "    if len(data) >= 3:\n",
        "        header = data[0]\n",
        "        data = data[1:3]\n",
        "\n",
        "        df = pd.DataFrame(data, columns=header)\n",
        "        file_name = 'vck.csv'\n",
        "        file_path = f'/content/{file_name}'\n",
        "        df.to_csv(file_path, index=False)\n",
        "\n",
        "        print(f\"Data extracted and saved to {file_path}\")\n",
        "    else:\n",
        "         print(f\"Expected 2 rows, but found {len(data)-1} rows.\")\n",
        "         exit()\n",
        "else:\n",
        "    print(\"Table not found on the webpage\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YCmkfU2AC6U1",
        "outputId": "f0441fee-4ea7-48d7-be33-ea596c65e163"
      },
      "execution_count": 362,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully accessed the website\n",
            "Data extracted and saved to /content/vck.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "url_cpoi = \"https://results.eci.gov.in/PcResultGenJune2024/partywisewinresultState-544.htm\"\n",
        "response = requests.get(url_cpoi)\n",
        "\n",
        "if response.status_code == 200:\n",
        "    print(\"Successfully accessed the website\")\n",
        "else:\n",
        "    print(\"Failed to access the website\")\n",
        "    exit()\n",
        "\n",
        "soup = BeautifulSoup(response.content, 'html.parser')\n",
        "table = soup.find('table')\n",
        "\n",
        "if table:\n",
        "    data = []\n",
        "    rows = table.find_all('tr')\n",
        "\n",
        "    for row in rows:\n",
        "        cols = row.find_all(['td', 'th'])\n",
        "        cols = [ele.text.strip() for ele in cols]\n",
        "        data.append(cols)\n",
        "\n",
        "    if len(data) >= 3:\n",
        "        header = data[0]\n",
        "        data = data[1:3]\n",
        "\n",
        "        df = pd.DataFrame(data, columns=header)\n",
        "        file_path = '/content/cpoi.csv'\n",
        "        df.to_csv(file_path, index=False)\n",
        "\n",
        "        print(f\"Data extracted and saved to {file_path}\")\n",
        "    else:\n",
        "        print(f\"Expected 2 rows, but found {len(data)-1} rows.\")\n",
        "        exit()\n",
        "else:\n",
        "    print(\"Table not found on the webpage\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U9LvA366EaiO",
        "outputId": "7017ff2c-21bf-438c-f28f-bba1f49ae501"
      },
      "execution_count": 363,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully accessed the website\n",
            "Data extracted and saved to /content/cpoi.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "url_rld = \"https://results.eci.gov.in/PcResultGenJune2024/partywisewinresultState-1458.htm\"\n",
        "response = requests.get(url_rld)\n",
        "\n",
        "if response.status_code == 200:\n",
        "    print(\"Successfully accessed the website\")\n",
        "else:\n",
        "    print(\"Failed to access the website\")\n",
        "    exit()\n",
        "\n",
        "soup = BeautifulSoup(response.content, 'html.parser')\n",
        "table = soup.find('table')\n",
        "\n",
        "if table:\n",
        "    data = []\n",
        "    rows = table.find_all('tr')\n",
        "\n",
        "    for row in rows:\n",
        "        cols = row.find_all(['td', 'th'])\n",
        "        cols = [ele.text.strip() for ele in cols]\n",
        "        data.append(cols)\n",
        "\n",
        "    if len(data) >= 3:\n",
        "        header = data[0]\n",
        "        data = data[1:3]\n",
        "\n",
        "        df = pd.DataFrame(data, columns=header)\n",
        "        file_path = '/content/rld.csv'\n",
        "        df.to_csv(file_path, index=False)\n",
        "\n",
        "        print(f\"Data extracted and saved to {file_path}\")\n",
        "    else:\n",
        "        print(f\"Expected 2 rows, but found {len(data)-1} rows.\")\n",
        "        exit()\n",
        "else:\n",
        "    print(\"Table not found on the webpage\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "arYOJYjfEwXK",
        "outputId": "3bcc640d-9118-4ad7-c9c9-1f986077eef8"
      },
      "execution_count": 364,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully accessed the website\n",
            "Data extracted and saved to /content/rld.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "url_jkn = \"https://results.eci.gov.in/PcResultGenJune2024/partywisewinresultState-834.htm\"\n",
        "response = requests.get(url_jkn)\n",
        "\n",
        "if response.status_code == 200:\n",
        "    print(\"Successfully accessed the website\")\n",
        "else:\n",
        "    print(\"Failed to access the website\")\n",
        "    exit()\n",
        "\n",
        "soup = BeautifulSoup(response.content, 'html.parser')\n",
        "table = soup.find('table')\n",
        "\n",
        "if table:\n",
        "    data = []\n",
        "    rows = table.find_all('tr')\n",
        "\n",
        "    for row in rows:\n",
        "        cols = row.find_all(['td', 'th'])\n",
        "        cols = [ele.text.strip() for ele in cols]\n",
        "        data.append(cols)\n",
        "\n",
        "    if len(data) >= 3:\n",
        "        header = data[0]\n",
        "        data = data[1:3]\n",
        "\n",
        "        df = pd.DataFrame(data, columns=header)\n",
        "        file_path = '/content/jkn.csv'\n",
        "        df.to_csv(file_path, index=False)\n",
        "\n",
        "        print(f\"Data extracted and saved to {file_path}\")\n",
        "    else:\n",
        "        print(f\"Expected 2 rows, but found {len(data)-1} rows.\")\n",
        "        exit()\n",
        "else:\n",
        "    print(\"Table not found on the webpage\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fYbsArM7E4SH",
        "outputId": "30bd78d6-fed8-4c63-cd33-63b16ddc6cb8"
      },
      "execution_count": 365,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully accessed the website\n",
            "Data extracted and saved to /content/jkn.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_data(url, file_name, num_rows=1):\n",
        "    response = requests.get(url)\n",
        "    if response.status_code == 200:\n",
        "        print(f\"Successfully accessed the website: {url}\")\n",
        "    else:\n",
        "        print(f\"Failed to access the website: {url}\")\n",
        "        return\n",
        "\n",
        "    soup = BeautifulSoup(response.content, 'html.parser')\n",
        "    table = soup.find('table')\n",
        "\n",
        "    if table:\n",
        "        data = []\n",
        "        rows = table.find_all('tr')\n",
        "\n",
        "        for row in rows:\n",
        "            cols = row.find_all(['td', 'th'])\n",
        "            cols = [ele.text.strip() for ele in cols]\n",
        "            data.append(cols)\n",
        "\n",
        "        if len(data) >= num_rows + 1:\n",
        "            header = data[0]\n",
        "            data = data[1:num_rows+1]\n",
        "\n",
        "            df = pd.DataFrame(data, columns=header)\n",
        "            file_path = f\"/content/{file_name}.csv\"\n",
        "            df.to_csv(file_path, index=False)\n",
        "\n",
        "            print(f\"Data extracted and saved to {file_path}\")\n",
        "        else:\n",
        "            print(f\"Expected {num_rows} rows, but found {len(data)-1} rows.\")\n",
        "    else:\n",
        "        print(f\"Table not found on the webpage: {url}\")\n",
        "\n",
        "urls = [\n",
        "    (\"https://results.eci.gov.in/PcResultGenJune2024/partywisewinresultState-1998.htm\", \"uppl\"),\n",
        "    (\"https://results.eci.gov.in/PcResultGenJune2024/partywisewinresultState-83.htm\", \"agp\"),\n",
        "    (\"https://results.eci.gov.in/PcResultGenJune2024/partywisewinresultState-664.htm\", \"hams\"),\n",
        "    (\"https://results.eci.gov.in/PcResultGenJune2024/partywisewinresultState-911.htm\", \"kec\"),\n",
        "    (\"https://results.eci.gov.in/PcResultGenJune2024/partywisewinresultState-1534.htm\", \"rsp\"),\n",
        "    (\"https://results.eci.gov.in/PcResultGenJune2024/partywisewinresultState-1142.htm\", \"cpn\"),\n",
        "    (\"https://results.eci.gov.in/PcResultGenJune2024/partywisewinresultState-3388.htm\", \"votp\"),\n",
        "    (\"https://results.eci.gov.in/PcResultGenJune2024/partywisewinresultState-2757.htm\", \"zpm\"),\n",
        "    (\"https://results.eci.gov.in/PcResultGenJune2024/partywisewinresultState-1584.htm\", \"sad\"),\n",
        "    (\"https://results.eci.gov.in/PcResultGenJune2024/partywisewinresultState-2484.htm\", \"rltp\"),\n",
        "    (\"https://results.eci.gov.in/PcResultGenJune2024/partywisewinresultState-3482.htm\", \"bhrt\"),\n",
        "    (\"https://results.eci.gov.in/PcResultGenJune2024/partywisewinresultState-1658.htm\", \"skm\"),\n",
        "    (\"https://results.eci.gov.in/PcResultGenJune2024/partywisewinresultState-1046.htm\", \"mdmk\"),\n",
        "    (\"https://results.eci.gov.in/PcResultGenJune2024/partywisewinresultState-2989.htm\", \"aspk\"),\n",
        "    (\"https://results.eci.gov.in/PcResultGenJune2024/partywisewinresultState-2070.htm\", \"adal\"),\n",
        "    (\"https://results.eci.gov.in/PcResultGenJune2024/partywisewinresultState-160.htm\", \"ajsup\"),\n",
        "    (\"https://results.eci.gov.in/PcResultGenJune2024/partywisewinresultState-118.htm\", \"aim\")\n",
        "]\n",
        "\n",
        "for url, file_name in urls:\n",
        "    extract_data(url, file_name)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8g2z2sjIJW0L",
        "outputId": "9e928876-0dd3-4eb9-cf9b-d4c05538a532"
      },
      "execution_count": 366,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully accessed the website: https://results.eci.gov.in/PcResultGenJune2024/partywisewinresultState-1998.htm\n",
            "Data extracted and saved to /content/uppl.csv\n",
            "Successfully accessed the website: https://results.eci.gov.in/PcResultGenJune2024/partywisewinresultState-83.htm\n",
            "Data extracted and saved to /content/agp.csv\n",
            "Successfully accessed the website: https://results.eci.gov.in/PcResultGenJune2024/partywisewinresultState-664.htm\n",
            "Data extracted and saved to /content/hams.csv\n",
            "Successfully accessed the website: https://results.eci.gov.in/PcResultGenJune2024/partywisewinresultState-911.htm\n",
            "Data extracted and saved to /content/kec.csv\n",
            "Successfully accessed the website: https://results.eci.gov.in/PcResultGenJune2024/partywisewinresultState-1534.htm\n",
            "Data extracted and saved to /content/rsp.csv\n",
            "Successfully accessed the website: https://results.eci.gov.in/PcResultGenJune2024/partywisewinresultState-1142.htm\n",
            "Data extracted and saved to /content/cpn.csv\n",
            "Successfully accessed the website: https://results.eci.gov.in/PcResultGenJune2024/partywisewinresultState-3388.htm\n",
            "Data extracted and saved to /content/votp.csv\n",
            "Successfully accessed the website: https://results.eci.gov.in/PcResultGenJune2024/partywisewinresultState-2757.htm\n",
            "Data extracted and saved to /content/zpm.csv\n",
            "Successfully accessed the website: https://results.eci.gov.in/PcResultGenJune2024/partywisewinresultState-1584.htm\n",
            "Data extracted and saved to /content/sad.csv\n",
            "Successfully accessed the website: https://results.eci.gov.in/PcResultGenJune2024/partywisewinresultState-2484.htm\n",
            "Data extracted and saved to /content/rltp.csv\n",
            "Successfully accessed the website: https://results.eci.gov.in/PcResultGenJune2024/partywisewinresultState-3482.htm\n",
            "Data extracted and saved to /content/bhrt.csv\n",
            "Successfully accessed the website: https://results.eci.gov.in/PcResultGenJune2024/partywisewinresultState-1658.htm\n",
            "Data extracted and saved to /content/skm.csv\n",
            "Successfully accessed the website: https://results.eci.gov.in/PcResultGenJune2024/partywisewinresultState-1046.htm\n",
            "Data extracted and saved to /content/mdmk.csv\n",
            "Successfully accessed the website: https://results.eci.gov.in/PcResultGenJune2024/partywisewinresultState-2989.htm\n",
            "Data extracted and saved to /content/aspk.csv\n",
            "Successfully accessed the website: https://results.eci.gov.in/PcResultGenJune2024/partywisewinresultState-2070.htm\n",
            "Data extracted and saved to /content/adal.csv\n",
            "Successfully accessed the website: https://results.eci.gov.in/PcResultGenJune2024/partywisewinresultState-160.htm\n",
            "Data extracted and saved to /content/ajsup.csv\n",
            "Successfully accessed the website: https://results.eci.gov.in/PcResultGenJune2024/partywisewinresultState-118.htm\n",
            "Data extracted and saved to /content/aim.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "url_indd = \"https://results.eci.gov.in/PcResultGenJune2024/partywisewinresultState-743.htm\"\n",
        "\n",
        "response = requests.get(url_indd)\n",
        "\n",
        "if response.status_code == 200:\n",
        "    print(\"Successfully accessed the website\")\n",
        "else:\n",
        "    print(\"Failed to access the website\")\n",
        "    exit()\n",
        "\n",
        "soup = BeautifulSoup(response.content, 'html.parser')\n",
        "table = soup.find('table')\n",
        "\n",
        "if table:\n",
        "    data = []\n",
        "    rows = table.find_all('tr')\n",
        "\n",
        "    for i, row in enumerate(rows[0:8]):\n",
        "        cols = row.find_all(['td', 'th'])\n",
        "        cols = [ele.text.strip() for ele in cols]\n",
        "        data.append(cols)\n",
        "\n",
        "    header = data[0]\n",
        "    data = data[1:]\n",
        "\n",
        "    df = pd.DataFrame(data, columns=header)\n",
        "\n",
        "    file_path = '/content/indd.csv'\n",
        "    df.to_csv(file_path, index=False)\n",
        "\n",
        "    print(f\"Data extracted and saved to {file_path}\")\n",
        "else:\n",
        "    print(\"Table not found on the webpage\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PG3f9MI2U-kZ",
        "outputId": "d26940dc-c43e-49a1-88e1-9841c79f23e6"
      },
      "execution_count": 367,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully accessed the website\n",
            "Data extracted and saved to /content/indd.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = \"/content/\"\n",
        "\n",
        "file_names = [\n",
        "    \"agp.csv\", \"ysr.csv\", \"tdp.csv\", \"inc.csv\", \"jkn.csv\",\n",
        "    \"dmk.csv\", \"hams.csv\", \"kec.csv\", \"sad.csv\", \"rltp.csv\",\n",
        "    \"adal.csv\", \"votp.csv\", \"skm.csv\", \"ss.csv\", \"jds.csv\",\n",
        "    \"rld.csv\", \"mdmk.csv\", \"aspk.csv\", \"rjd.csv\", \"shs.csv\",\n",
        "    \"uppl.csv\", \"vck.csv\", \"indd.csv\", \"rsp.csv\", \"jnp.csv\",\n",
        "    \"ml.csv\", \"ncp.csv\", \"jmm.csv\", \"sp.csv\", \"zpm.csv\",\n",
        "    \"ajsup.csv\", \"cpoi.csv\", \"jd.csv\", \"cpi.csv\", \"cpn.csv\",\n",
        "    \"bhrt.csv\", \"aap.csv\", \"bjp.csv\", \"aim.csv\", \"ljp.csv\",\n",
        "    \"iuml.csv\", \"aitc.csv\"\n",
        "]\n",
        "\n",
        "dataframes = {}\n",
        "\n",
        "party_names = {\n",
        "    \"bjp\": \"Bharatiya Janata Party\",\n",
        "    \"inc\": \"Indian National Congress\",\n",
        "    \"sp\": \"Samajwadi Party\",\n",
        "    \"aitc\": \"All India Trinamool Congress\",\n",
        "    \"dmk\": \"Dravida Munnetra Kazhagam\",\n",
        "    \"tdp\": \"Telugu Desam\",\n",
        "    \"jd\": \"Janata Dal (United)\",\n",
        "    \"ss\": \"Shiv Sena (Uddhav Balasaheb Thackrey)\",\n",
        "    \"ncp\": \"Nationalist Congress Party  Sharadchandra Pawar\",\n",
        "    \"shs\": \"Shiv Sena\",\n",
        "    \"ljp\": \"Lok Janshakti Party(Ram Vilas)\",\n",
        "    \"ysr\": \"Yuvajana Sramika Rythu Congress Party\",\n",
        "    \"rjd\": \"Rashtriya Janata Dal\",\n",
        "    \"cpi\": \"Communist Party of India (Marxist)\",\n",
        "    \"iuml\": \"Indian Union Muslim League\",\n",
        "    \"aap\": \"Aam Aadmi Party\",\n",
        "    \"jmm\": \"Jharkhand Mukti Morcha\",\n",
        "    \"jnp\": \"Janasena Party\",\n",
        "    \"ml\": \"Communist Party of India (Marxist-Leninist) (Liberation)\",\n",
        "    \"jds\": \"Janata Dal (Secular)\",\n",
        "    \"vck\": \"Viduthalai Chiruthaigal Katchi\",\n",
        "    \"cpoi\": \"Communist Party of India\",\n",
        "    \"rld\": \"Rashtriya Lok Dal\",\n",
        "    \"jkn\": \"Jammu & Kashmir National Conference\",\n",
        "    \"uppl\": \"United Peoples Party, Liberal\",\n",
        "    \"agp\": \"Asom Gana Parishad\",\n",
        "    \"hams\": \"Hindustani Awam Morcha (Secular)\",\n",
        "    \"kec\": \"Kerala Congress\",\n",
        "    \"rsp\": \"Revolutionary Socialist Party\",\n",
        "    \"cpn\": \"Nationalist Congress Party\",\n",
        "    \"votp\": \"Voice of the People Party\",\n",
        "    \"zpm\": \"Zoram Peoples Movement\",\n",
        "    \"sad\": \"Shiromani Akali Dal\",\n",
        "    \"rltp\": \"Rashtriya Loktantrik Party\",\n",
        "    \"bhrt\": \"Bharat Adivasi Party\",\n",
        "    \"skm\": \"Sikkim Krantikari Morcha\",\n",
        "    \"mdmk\": \"Marumalarchi Dravida Munnetra Kazhagam\",\n",
        "    \"aspk\": \"Aazad Samaj Party (Kanshi Ram)\",\n",
        "    \"adal\": \"Apna Dal (Soneylal)\",\n",
        "    \"ajsup\": \"AJSU Party\",\n",
        "    \"aim\": \"All India Majlis-E-Ittehadul Muslimeen\",\n",
        "    \"indd\": \"Independent\"\n",
        "}\n",
        "\n",
        "for file_name in file_names:\n",
        "    df = pd.read_csv(f\"{file_path}{file_name}\")\n",
        "    short_name = file_name.split('.')[0]\n",
        "    full_name = party_names.get(short_name, \"Unknown Party\")\n",
        "    df[\"Party\"] = full_name\n",
        "    dataframes[file_name] = df\n",
        "\n",
        "merged_df = pd.concat(dataframes.values(), ignore_index=True)\n",
        "\n",
        "print(merged_df.head())\n",
        "\n",
        "merged_df.to_csv(f\"{file_path}merged_data.csv\", index=False)\n",
        "print(\"Merged data saved to merged_data.csv\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OtDAcIwwS4js",
        "outputId": "13384919-c73f-4ae1-f465-be1a51f48b17"
      },
      "execution_count": 368,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   S.No Parliament Constituency       Winning Candidate Total Votes  Margin  \\\n",
            "0     1              Barpeta(3)  PHANI BHUSAN CHOUDHURY      860113  222351   \n",
            "1     1           Araku (ST)(1)      GUMMA THANUJA RANI      477005   50580   \n",
            "2     2              Kadapa(21)     Y. S. AVINASH REDDY      605143   62695   \n",
            "3     3      Thirupathi(SC)(23)     GURUMOORTHY MADDILA      632228   14569   \n",
            "4     4            Rajampet(24)        P V MIDHUN REDDY      644844   76071   \n",
            "\n",
            "                                   Party  \n",
            "0                     Asom Gana Parishad  \n",
            "1  Yuvajana Sramika Rythu Congress Party  \n",
            "2  Yuvajana Sramika Rythu Congress Party  \n",
            "3  Yuvajana Sramika Rythu Congress Party  \n",
            "4  Yuvajana Sramika Rythu Congress Party  \n",
            "Merged data saved to merged_data.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = 'merged_data.csv'\n",
        "\n",
        "merged_data = pd.read_csv(file_path)\n",
        "\n",
        "sorted_data = merged_data.sort_values(by='Total Votes', ascending=False)\n",
        "\n",
        "print(sorted_data.head())\n",
        "\n",
        "sorted_data.to_csv('sorted_merged_data.csv', index=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i8shcK2ivlFs",
        "outputId": "83e8937d-ba8e-4b63-9705-b9ba917cbd8f"
      },
      "execution_count": 369,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     S.No Parliament Constituency  Winning Candidate Total Votes  Margin  \\\n",
            "490   226           Malkajgiri(7)    EATALA RAJENDER      991042  391475   \n",
            "339    75     Bangalore North(24)  SHOBHA KARANDLAJE      986049  259476   \n",
            "362    98              BHOPAL(19)        ALOK SHARMA      981109  501499   \n",
            "468   204                 DURG(7)       VIJAY BAGHEL      956497  438226   \n",
            "366   102            MANDSOUR(23)      SUDHEER GUPTA      945761  500655   \n",
            "\n",
            "                      Party  \n",
            "490  Bharatiya Janata Party  \n",
            "339  Bharatiya Janata Party  \n",
            "362  Bharatiya Janata Party  \n",
            "468  Bharatiya Janata Party  \n",
            "366  Bharatiya Janata Party  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "total_seats = merged_df.shape[0]\n",
        "max_seats = merged_df['Party'].value_counts().max()\n",
        "party_with_max_seats = merged_df['Party'].value_counts().idxmax()\n",
        "\n",
        "print(f\"1. Total seats: {total_seats}\")\n",
        "print(f\"\\n2. Maximum seats won by any party: {max_seats}\")\n",
        "print(f\"\\n3. Party with the maximum seats: {party_with_max_seats}\")\n",
        "party_seat_count = merged_df['Party'].value_counts()\n",
        "print(f\"\\n4. List of Parties with their Total Wons:\\n\\n {party_seat_count}\")\n",
        "nda_parties = ['bjp', 'ajsup', 'adal', 'agp', 'jnp', 'jds', 'jd', 'ljp', 'ncp', 'shs', 'skm', 'tdp', 'uppl', 'hams']\n",
        "\n",
        "print(\"\\n5. Parties won under N.D alliance:\")\n",
        "print(nda_parties)\n",
        "print(\"\\n6. Total Seats won by N.D.A: 293\")\n",
        "indi_parties = ['aap', 'cpi', 'inc', 'dmk', 'aitc', 'ss', 'sp', 'ncp', 'iuml', 'jkn', 'cpoi', 'jmm', 'vck', 'rsp', 'rjd', 'mdmk', 'ml', 'kec', 'rltp']\n",
        "print(\"\\n7. Parties won under I.N.D.I alliance:\")\n",
        "print(indi_parties)\n",
        "print(\"\\n8. Total Seats won by I.N.D.I.A: 233\")\n",
        "print(\"\\n9. Winning candidates under each party:\")\n",
        "print(\"Party           Winning Candidate\")\n",
        "file_names = [\n",
        "    \"agp.csv\", \"ysr.csv\", \"tdp.csv\", \"inc.csv\", \"jkn.csv\",\n",
        "    \"dmk.csv\", \"hams.csv\", \"kec.csv\", \"sad.csv\", \"rltp.csv\",\n",
        "    \"adal.csv\", \"votp.csv\", \"skm.csv\", \"ss.csv\", \"jds.csv\",\n",
        "    \"rld.csv\", \"mdmk.csv\", \"aspk.csv\", \"rjd.csv\", \"shs.csv\",\n",
        "    \"uppl.csv\", \"vck.csv\", \"indd.csv\", \"rsp.csv\", \"jnp.csv\",\n",
        "    \"ml.csv\", \"ncp.csv\", \"jmm.csv\", \"sp.csv\", \"zpm.csv\",\n",
        "    \"ajsup.csv\", \"cpoi.csv\", \"jd.csv\", \"cpi.csv\", \"cpn.csv\",\n",
        "    \"bhrt.csv\", \"aap.csv\", \"bjp.csv\", \"aim.csv\", \"ljp.csv\",\n",
        "    \"iuml.csv\", \"aitc.csv\"\n",
        "]\n",
        "\n",
        "winning_candidates = {}\n",
        "\n",
        "for file_name in file_names:\n",
        "    df = pd.read_csv(file_name)\n",
        "\n",
        "    if 'Winning Candidate' in df.columns:\n",
        "        winning_candidate = df['Winning Candidate'].iloc[0]\n",
        "        party_name = file_name.replace('.csv', '')\n",
        "        winning_candidates[party_name] = winning_candidate\n",
        "\n",
        "for party, candidate in winning_candidates.items():\n",
        "    print(f\"{party}          {candidate}\")\n",
        "\n",
        "file_path = 'sorted_merged_data.csv'\n",
        "\n",
        "# Load the CSV file into a DataFrame\n",
        "sorted_data = pd.read_csv(file_path)\n",
        "\n",
        "print(\"\\n10. Winning candidate details:\")\n",
        "print(sorted_data.head(1))\n",
        "\n",
        "print(\"\\n11. Party ruling the country: Bhartiya Janata Party(bjp)\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NWHdAUXWTKi8",
        "outputId": "8fbd3617-d439-43e2-a025-9fb08d29a417"
      },
      "execution_count": 370,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1. Total seats: 543\n",
            "\n",
            "2. Maximum seats won by any party: 240\n",
            "\n",
            "3. Party with the maximum seats: Bharatiya Janata Party\n",
            "\n",
            "4. List of Parties with their Total Wons:\n",
            "\n",
            " Party\n",
            "Bharatiya Janata Party                                      240\n",
            "Indian National Congress                                     99\n",
            "Samajwadi Party                                              37\n",
            "All India Trinamool Congress                                 29\n",
            "Dravida Munnetra Kazhagam                                    22\n",
            "Telugu Desam                                                 16\n",
            "Janata Dal (United)                                          12\n",
            "Shiv Sena (Uddhav Balasaheb Thackrey)                         9\n",
            "Nationalist Congress Party  Sharadchandra Pawar              8\n",
            "Shiv Sena                                                     7\n",
            "Independent                                                   7\n",
            "Lok Janshakti Party(Ram Vilas)                                5\n",
            "Communist Party of India (Marxist)                            4\n",
            "Yuvajana Sramika Rythu Congress Party                         4\n",
            "Rashtriya Janata Dal                                          4\n",
            "Aam Aadmi Party                                               3\n",
            "Indian Union Muslim League                                    3\n",
            "Jharkhand Mukti Morcha                                        3\n",
            "Communist Party of India                                      2\n",
            "Communist Party of India (Marxist-Leninist) (Liberation)      2\n",
            "Janasena Party                                                2\n",
            "Viduthalai Chiruthaigal Katchi                                2\n",
            "Jammu & Kashmir National Conference                           2\n",
            "Rashtriya Lok Dal                                             2\n",
            "Janata Dal (Secular)                                          2\n",
            "United Peoples Party, Liberal                                1\n",
            "Rashtriya Loktantrik Party                                    1\n",
            "Hindustani Awam Morcha (Secular)                              1\n",
            "All India Majlis-E-Ittehadul Muslimeen                        1\n",
            "Kerala Congress                                               1\n",
            "Shiromani Akali Dal                                           1\n",
            "Bharat Adivasi Party                                          1\n",
            "Nationalist Congress Party                                    1\n",
            "Apna Dal (Soneylal)                                           1\n",
            "Revolutionary Socialist Party                                 1\n",
            "Voice of the People Party                                     1\n",
            "AJSU Party                                                    1\n",
            "Zoram Peoples Movement                                       1\n",
            "Sikkim Krantikari Morcha                                      1\n",
            "Marumalarchi Dravida Munnetra Kazhagam                        1\n",
            "Aazad Samaj Party (Kanshi Ram)                                1\n",
            "Asom Gana Parishad                                            1\n",
            "Name: count, dtype: int64\n",
            "\n",
            "5. Parties won under N.D alliance:\n",
            "['bjp', 'ajsup', 'adal', 'agp', 'jnp', 'jds', 'jd', 'ljp', 'ncp', 'shs', 'skm', 'tdp', 'uppl', 'hams']\n",
            "\n",
            "6. Total Seats won by N.D.A: 293\n",
            "\n",
            "7. Parties won under I.N.D.I alliance:\n",
            "['aap', 'cpi', 'inc', 'dmk', 'aitc', 'ss', 'sp', 'ncp', 'iuml', 'jkn', 'cpoi', 'jmm', 'vck', 'rsp', 'rjd', 'mdmk', 'ml', 'kec', 'rltp']\n",
            "\n",
            "8. Total Seats won by I.N.D.I.A: 233\n",
            "\n",
            "9. Winning candidates under each party:\n",
            "Party           Winning Candidate\n",
            "agp          PHANI BHUSAN CHOUDHURY\n",
            "ysr          GUMMA THANUJA RANI\n",
            "tdp          KINJARAPU RAMMOHAN NAIDU\n",
            "inc          RAKIBUL HUSSAIN\n",
            "jkn          AGA SYED RUHULLAH MEHDI\n",
            "dmk          DR.KALANIDHI VEERASWAMY\n",
            "hams          JITAN RAM MANJHI\n",
            "kec          ADV K FRANCIS GEORGE\n",
            "sad          HARSIMRAT KAUR BADAL\n",
            "rltp          HANUMAN BENIWAL\n",
            "adal          ANUPRIYA PATEL\n",
            "votp          DR. RICKY ANDREW J. SYNGKON\n",
            "skm          INDRA HANG SUBBA\n",
            "ss          SANJAY UTTAMRAO DESHMUKH\n",
            "jds          H.D. KUMARASWAMY\n",
            "rld          CHANDAN CHAUHAN\n",
            "mdmk          DURAI VAIKO\n",
            "aspk          CHANDRASHEKHAR\n",
            "rjd          MISHA BHARTI\n",
            "shs          JADHAV PRATAPRAO GANPATRAO\n",
            "uppl          JOYANTA BASUMATARY\n",
            "vck          RAVIKUMAR. D\n",
            "indd          RAJESH RANJAN ALIAS PAPPU YADAV\n",
            "rsp          N K PREMACHANDRAN\n",
            "jnp          TANGELLA UDAY SRINIVAS (TEA TIME UDAY)\n",
            "ml          SUDAMA PRASAD\n",
            "ncp          AMAR SHARADRAO KALE\n",
            "jmm          VIJAY KUMAR HANSDAK\n",
            "sp          IQRA CHOUDHARY\n",
            "zpm          RICHARD VANLALHMANGAIHA\n",
            "ajsup          CHANDRA PRAKASH CHOUDHARY\n",
            "cpoi          SUBBARAYAN, K.\n",
            "jd          SUNIL KUMAR\n",
            "cpi          K.RADHAKRISHNAN\n",
            "cpn          TATKARE SUNIL DATTATREY\n",
            "bhrt          RAJ KUMAR ROAT\n",
            "aap          DR. RAJ KUMAR CHABBEWAL\n",
            "bjp          C.M.RAMESH\n",
            "aim          ASADUDDIN OWAISI\n",
            "ljp          VEENA DEVI\n",
            "iuml          E.T.  MOHAMMED BASHEER\n",
            "aitc          JAGADISH CHANDRA BARMA BASUNIA\n",
            "\n",
            "10. Winning candidate details:\n",
            "   S.No Parliament Constituency Winning Candidate Total Votes  Margin  \\\n",
            "0   226           Malkajgiri(7)   EATALA RAJENDER      991042  391475   \n",
            "\n",
            "                    Party  \n",
            "0  Bharatiya Janata Party  \n",
            "\n",
            "11. Party ruling the country: Bhartiya Janata Party(bjp)\n"
          ]
        }
      ]
    }
  ]
}